{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89660c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run headers.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cadc8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(X, y,z,start,val):\n",
    "    fig = plt.figure(figsize=(17, 17))\n",
    "    if len(z)==0 :\n",
    "        index=start\n",
    "        for i in range(0,val*2-start*2,2):\n",
    "            fig.add_subplot(val,2,i+1)\n",
    "            plt.imshow(X[index])\n",
    "            plt.axis('off')\n",
    "\n",
    "            fig.add_subplot(val,2,i+2)\n",
    "            plt.imshow(y[index])\n",
    "            plt.axis('off')\n",
    "            index+=1\n",
    "    else:\n",
    "        index=start\n",
    "        for i in range(0,val*3-start*3,3):\n",
    "            fig.add_subplot(val,3,i+1)\n",
    "            plt.imshow(X[index])\n",
    "            plt.axis('off')\n",
    "\n",
    "            fig.add_subplot(val,3,i+2)\n",
    "            plt.imshow(y[index])\n",
    "            plt.axis('off')\n",
    "            \n",
    "            fig.add_subplot(val,3,i+3)\n",
    "            plt.imshow(z[index])\n",
    "            plt.axis('off')\n",
    "            \n",
    "            index+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31788d08",
   "metadata": {},
   "source": [
    "### Model Visualisation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3df7daad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def conv_block_visual(input_, num_filters):\n",
    "    return Conv2D(filters = num_filters,kernel_size =  3, padding=\"same\")(input_)\n",
    "\n",
    "def encoder_block_visual(input_, num_filters):\n",
    "    conv = conv_block_visual(input_, num_filters)\n",
    "    pool = MaxPool2D((2, 2))(conv)\n",
    "    return conv, pool\n",
    "\n",
    "def gating_signal_visual(input_,num_filters):\n",
    "    return Conv2D(filters = num_filters,kernel_size =  3,strides = (1, 1), padding='same')(input_)\n",
    "\n",
    "def attention_gate_visual(input_,gating_input,num_filters):\n",
    "\n",
    "    shape_conv_inp = keras.int_shape(input_)\n",
    "\n",
    "    conv_inp = Conv2D(num_filters, (3,3), strides=(2, 2), padding='same')(input_)\n",
    "\n",
    "    gating_conv_concat = add([conv_inp,gating_input])\n",
    "    pixel_weight = Conv2D(1,(1,1),padding='same')(gating_conv_concat)\n",
    "    shape_sigmoid = keras.int_shape(pixel_weight)\n",
    "    upsample_shape_sigmoid = UpSampling2D(size=(shape_conv_inp[1] // shape_sigmoid[1], shape_conv_inp[2] // shape_sigmoid[2]))(pixel_weight)\n",
    "    upsample_psi = Lambda(lambda x, repnum: keras.repeat_elements(x, repnum, axis=3),arguments={'repnum': shape_conv_inp[3]}) (upsample_shape_sigmoid)\n",
    "\n",
    "    y = multiply([upsample_psi, input_])\n",
    "    result = Conv2D(shape_conv_inp[3], (1, 1), padding='same')(y)\n",
    "\n",
    "    return result\n",
    "\n",
    "def decoder_block_visual(input_, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(filters = num_filters,kernel_size = (2, 2), strides=2, padding=\"same\")(input_)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block_visual(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def unet_build_visual(input_shape):\n",
    "\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    conv1, pool1 = encoder_block_visual(inputs, 32)\n",
    "    conv2, pool2 = encoder_block_visual(pool1, 64)\n",
    "    conv3, pool3 = encoder_block_visual(pool2, 128) \n",
    "    conv4, pool4 = encoder_block_visual(pool3, 256) \n",
    "\n",
    "    bridge = conv_block_visual(pool4, 512)\n",
    "\n",
    "    decoder_1 = decoder_block_visual(bridge, conv4, 256)\n",
    "    decoder_2 = decoder_block_visual(decoder_1, conv3, 128)\n",
    "    decoder_3 = decoder_block_visual(decoder_2, conv2, 64)\n",
    "    decoder_4 = decoder_block_visual(decoder_3, conv1, 32)\n",
    "\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\") (decoder_4)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model\n",
    "\n",
    "def attention_unet_build_visual(input_shape):\n",
    "\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    #encode\n",
    "    conv1, pool1 = encoder_block_visual(inputs, 32)\n",
    "    conv2, pool2 = encoder_block_visual(pool1, 64)\n",
    "    conv3, pool3 = encoder_block_visual(pool2, 128) \n",
    "    conv4, pool4 = encoder_block_visual(pool3, 256) \n",
    "\n",
    "    #bridge\n",
    "    bridge = conv_block_visual(pool4, 512)\n",
    "\n",
    "    #gating,#attention,#decode\n",
    "    gating_signal_1 = gating_signal_visual(bridge,256)\n",
    "    attention_1 = attention_gate_visual(conv4,gating_signal_1,256)\n",
    "    decoder_1 = decoder_block_visual(bridge, attention_1, 256)\n",
    "\n",
    "    #gating,#attention,#decode\n",
    "    gating_signal_2 = gating_signal_visual(decoder_1,128)\n",
    "    attention_2 = attention_gate_visual(conv3,gating_signal_2,128)\n",
    "    decoder_2 = decoder_block_visual(decoder_1, attention_2, 128)\n",
    "\n",
    "    #gating,#attention,#decode\n",
    "    gating_signal_3 = gating_signal_visual(decoder_2,64)\n",
    "    attention_3 = attention_gate_visual(conv2,gating_signal_3,64)\n",
    "    decoder_3 = decoder_block_visual(decoder_2, attention_3, 64)\n",
    "\n",
    "    #gating,#attention,#decode\n",
    "    gating_signal_4 = gating_signal_visual(decoder_3,32)\n",
    "    attention_4 = attention_gate_visual(conv1,gating_signal_4,32)\n",
    "    decoder_4 = decoder_block_visual(decoder_3, attention_4, 32)\n",
    "\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\") (decoder_4)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"AU-Net\")\n",
    "    return model\n",
    "\n",
    "def plot_AUNet_(input_shape):\n",
    "    model_visual = attention_unet_build_visual(input_shape)\n",
    "    return plot_model(model_visual,show_shapes=True,show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96)\n",
    "\n",
    "def plot_UNet_(input_shape):\n",
    "    model_visual = unet_build_visual(input_shape)\n",
    "    return plot_model(model_visual,show_shapes=True,show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38287106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val_loss_(history):\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('binary_crossentropy')\n",
    "    plt.savefig('model_training_history')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11aa7928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_single(img_arr):\n",
    "    fig = plt.figure(figsize=(17, 17))\n",
    "    x=1\n",
    "    for img in img_arr:\n",
    "        fig.add_subplot(1,len(img_arr)+1,x)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        x+=1\n",
    "        \n",
    "    fig.add_subplot(1,len(img_arr)+1,x)\n",
    "    plt.imshow(model_best.predict(np.array([img_arr[0]]))[0])\n",
    "    plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
