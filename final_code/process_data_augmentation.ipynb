{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b3247c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split_=0.7\n",
    "train_valid_split_=0.75 #after augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb6c4449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from imageio import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import shutil\n",
    "import time\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f2fe97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "####################################         AUGMENTATION            ###################################################\n",
    "########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65f5772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def light_augmentation(image,mask):\n",
    "    aug = A.Compose([\n",
    "        A.VerticalFlip(p=0.5),              \n",
    "        A.RandomRotate90(p=0.5)]\n",
    "    )\n",
    "\n",
    "    augmented = aug(image=image, mask=mask)\n",
    "\n",
    "    image_light = augmented['image']\n",
    "    mask_light = augmented['mask']\n",
    "    \n",
    "    aug = A.Compose([\n",
    "        A.VerticalFlip(p=0.5),              \n",
    "        A.RandomRotate90(p=0.5)]\n",
    "    )\n",
    "\n",
    "    augmented = aug(image=image, mask=mask)\n",
    "\n",
    "    image_light = augmented['image']\n",
    "    mask_light = augmented['mask']\n",
    "    \n",
    "    return (image_light,mask_light)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74aa8723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def medium_augmentation(image,mask):\n",
    "    aug = A.Compose([\n",
    "        A.RandomSizedCrop(min_max_height=(100, 101), height=256, width=256, p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.OneOf([\n",
    "            A.ElasticTransform(p=0.5, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
    "            A.GridDistortion(p=0.5),\n",
    "            A.OpticalDistortion(distort_limit=1, shift_limit=0.5, p=1),\n",
    "        ], p=0.8)])\n",
    "\n",
    "    augmented = aug(image=image, mask=mask)\n",
    "\n",
    "    image_medium = augmented['image']\n",
    "    mask_medium = augmented['mask']\n",
    "    \n",
    "    return (image_medium,mask_medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d78cb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heavy_augmentation(image,mask):\n",
    "    aug = A.Compose([\n",
    "#         A.RandomSizedCrop(min_max_height=(100, 101), height=256, width=256, p=0.5),\n",
    "        A.VerticalFlip(p=0.5),              \n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.OneOf([\n",
    "            A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=0.5),\n",
    "            A.GridDistortion(p=0.5),\n",
    "            A.OpticalDistortion(distort_limit=1, shift_limit=0.5, p=1)                  \n",
    "            ], p=0.8),\n",
    "        A.CLAHE(p=0.8),\n",
    "        A.RandomBrightnessContrast(p=0.8),    \n",
    "        A.RandomGamma(p=0.8)])\n",
    "\n",
    "    augmented = aug(image=image, mask=mask)\n",
    "\n",
    "    image_heavy = augmented['image']\n",
    "    mask_heavy = augmented['mask']\n",
    "    \n",
    "    return (image_heavy,mask_heavy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd52c18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "####################################           KeyVars           #######################################################\n",
    "########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e25f0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=\"before_augment/\"\n",
    "subdir=[\"benign_image/\",\"benign_mask/\",\"malignant_image/\",\"malignant_mask/\",\"normal_image/\",\"normal_mask/\"]\n",
    "dataset=['dataset/','train/','test/','validation/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ef31bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "####################################         StoreData           #######################################################\n",
    "########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e48509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StoreData(directory,subdir):\n",
    "    for data in dataset:\n",
    "        if data=='dataset/':\n",
    "            if os.path.exists(data):\n",
    "                shutil.rmtree(data)\n",
    "            os.makedirs(data)\n",
    "        else:\n",
    "            if os.path.exists('dataset/'+data):\n",
    "                shutil.rmtree('dataset/'+data)\n",
    "            os.makedirs('dataset/'+data)\n",
    "            for sub in subdir:\n",
    "                if os.path.exists('dataset/'+data+sub):\n",
    "                    shutil.rmtree('dataset/'+data+sub)\n",
    "                os.makedirs('dataset/'+data+sub)\n",
    "\n",
    "    for i in range(3):\n",
    "        print(f\"{subdir[i*2][:-1]} : {len(os.listdir(directory+subdir[i*2]))}\")\n",
    "        print()\n",
    "\n",
    "        l=[]\n",
    "        for j in range(len(os.listdir(directory+subdir[i*2]))):\n",
    "            l.append(plt.imread(directory+subdir[i*2]+os.listdir(directory+subdir[i*2])[j]))\n",
    "\n",
    "        l2=[]\n",
    "        for j in range(len(os.listdir(directory+subdir[i*2+1]))):\n",
    "            l2.append(plt.imread(directory+subdir[i*2+1]+os.listdir(directory+subdir[i*2+1])[j]))\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(l, l2, train_size=train_test_split_)\n",
    "\n",
    "        X_aug=[] ; y_aug=[] ;\n",
    "\n",
    "        for j in range(400-len(X_train)):\n",
    "            if j<len(X_train):\n",
    "                image,mask = heavy_augmentation(X_train[j],y_train[j])\n",
    "                X_aug.append(image) ; y_aug.append(mask)\n",
    "            else:\n",
    "                k = j\n",
    "                while(k>len(X_train)):\n",
    "                    k-=len(X_train)\n",
    "                image,mask = heavy_augmentation(X_train[k-len(X_train)],y_train[k-len(X_train)])\n",
    "                X_aug.append(image) ; y_aug.append(mask)\n",
    "\n",
    "        X_train1, X_val1, y_train1, y_val1 = train_test_split(X_train, y_train, train_size=train_valid_split_)\n",
    "        X_train2, X_val2, y_train2, y_val2 = train_test_split(X_aug, y_aug, train_size=train_valid_split_)\n",
    "\n",
    "        for j in range(len(X_train1)):\n",
    "            plt.imsave(\"dataset/train/\"+subdir[i*2]+str(j)+\".jpeg\", X_train1[j])\n",
    "    #             plt.imsave(\"dataset/train/\"+subdir[i*2+1]+str(j)+\".jpeg\", y_train1[j].reshape(256, 256))\n",
    "            Image.fromarray(y_train1[j]).save(\"dataset/train/\"+subdir[i*2+1]+str(j)+\".jpeg\")\n",
    "\n",
    "        for j in range(len(X_train2)):\n",
    "            plt.imsave(\"dataset/train/\"+subdir[i*2]+str(len(X_train1)+j)+\".jpeg\", X_train2[j])\n",
    "    #             plt.imsave(\"dataset/train/\"+subdir[i*2+1]+str(len(X_train1)+j)+\".jpeg\", y_train2[j].reshape(256, 256))\n",
    "            Image.fromarray(y_train2[j]).save(\"dataset/train/\"+subdir[i*2+1]+str(len(X_train1)+j)+\".jpeg\")\n",
    "\n",
    "        for j in range(len(X_val1)):\n",
    "            plt.imsave(\"dataset/validation/\"+subdir[i*2]+str(j)+\".jpeg\", X_val1[j])\n",
    "    #             plt.imsave(\"dataset/validation/\"+subdir[i*2+1]+str(j)+\".jpeg\", y_val1[j].reshape(256, 256))\n",
    "            Image.fromarray(y_val1[j]).save(\"dataset/validation/\"+subdir[i*2+1]+str(j)+\".jpeg\")\n",
    "\n",
    "        for j in range(len(X_val2)):\n",
    "            plt.imsave(\"dataset/validation/\"+subdir[i*2]+str(j+len(X_val1))+\".jpeg\", X_val2[j])\n",
    "    #             plt.imsave(\"dataset/validation/\"+subdir[i*2+1]+str(j+len(X_val1))+\".jpeg\", y_val2[j].reshape(256, 256))\n",
    "            Image.fromarray(y_val2[j]).save(\"dataset/validation/\"+subdir[i*2+1]+str(j+len(X_val1))+\".jpeg\")\n",
    "\n",
    "        for j in range(len(X_test)):\n",
    "            plt.imsave(\"dataset/test/\"+subdir[i*2]+str(j)+\".jpeg\", X_test[j])\n",
    "    #             plt.imsave(\"dataset/test/\"+subdir[i*2+1]+str(j)+\".jpeg\", y_test[j].reshape(256, 256))\n",
    "            Image.fromarray(y_test[j]).save(\"dataset/test/\"+subdir[i*2+1]+str(j)+\".jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfab4c28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign_image : 437\n",
      "\n",
      "malignant_image : 210\n",
      "\n",
      "normal_image : 133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "StoreData(directory,subdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09fa1ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n",
      "299\n",
      "299\n",
      "\n",
      "132\n",
      "63\n",
      "40\n",
      "\n",
      "101\n",
      "101\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('dataset/train/benign_image')))\n",
    "print(len(os.listdir('dataset/train/malignant_image')))\n",
    "print(len(os.listdir('dataset/train/normal_image')))\n",
    "print()\n",
    "print(len(os.listdir('dataset/test/benign_image')))\n",
    "print(len(os.listdir('dataset/test/malignant_image')))\n",
    "print(len(os.listdir('dataset/test/normal_image')))\n",
    "print()\n",
    "print(len(os.listdir('dataset/validation/benign_image')))\n",
    "print(len(os.listdir('dataset/validation/malignant_image')))\n",
    "print(len(os.listdir('dataset/validation/normal_image')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
